{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT using German to English.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDeCb5adKz2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "837ebe50-77d6-4f7b-d614-8d5b22a5d4ad"
      },
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr__X0v9LOkn",
        "colab_type": "text"
      },
      "source": [
        "**Data Set read**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUTx-AH4LAYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to read raw text file\n",
        "def read_text(filename):\n",
        "    # open the file\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVoX3eRhLeG8",
        "colab_type": "text"
      },
      "source": [
        "function to split the text into English-German pairs separated by '\\n' and then split these pairs into English sentences and German sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GmeUk-6LZq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a text into sentences\n",
        "def to_lines(text):\n",
        "    sents = text.strip().split('\\n')\n",
        "    sents = [i.split('\\t') for i in sents]\n",
        "    return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vddbjAOhLoZx",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "970b2448-b99c-4693-df65-3120a93cf07e"
      },
      "source": [
        "#upload dataset\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c629257e-65e0-4e52-b2db-13b37ceea5d2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c629257e-65e0-4e52-b2db-13b37ceea5d2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving deu.txt to deu.txt\n",
            "User uploaded file \"deu.txt\" with length 14118330 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuCPOeeOL7Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_text(\"deu.txt\")\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = array(deu_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "173leR2DOGPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c4b8f8bd-8731-48d7-bfd6-aeda24e86b97"
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Hi.', 'Hallo!'],\n",
              "       ['Hi.', 'Grüß Gott!'],\n",
              "       ['Run!', 'Lauf!'],\n",
              "       ...,\n",
              "       [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n",
              "        'Wenn jemand Fremdes dir sagt, dass du dich wie ein Muttersprachler anhörst, bedeutet das wahrscheinlich: Er hat etwas an deinem Sprechen bemerkt, dass dich als Nicht-Muttersprachler verraten hat. Mit anderen Worten: Du hörst dich nicht wirklich wie ein Muttersprachler an.'],\n",
              "       ['It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.',\n",
              "        'Es ist wohl unmöglich, einen vollkommen fehlerfreien Korpus zu erreichen\\xa0— das liegt in der Natur eines solchen Gemeinschaftsprojekts. Doch wenn wir unsere Mitglieder dazu bringen können, nicht mit Sprachen herumzuexperimentieren, die sie gerade lernen, sondern Sätze in ihrer eigenen Muttersprache beizutragen, dann gelingt es uns vielleicht, die Zahl der Fehler klein zu halten.'],\n",
              "       ['Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.',\n",
              "        'Ohne Zweifel findet sich auf dieser Welt zu jedem Mann genau die richtige Ehefrau und umgekehrt; wenn man jedoch in Betracht zieht, dass ein Mensch nur Gelegenheit hat, mit ein paar hundert anderen bekannt zu sein, von denen ihm nur ein Dutzend oder weniger nahesteht, darunter höchstens ein oder zwei Freunde, dann erahnt man eingedenk der Millionen Einwohner dieser Welt\\xa0leicht, dass seit Erschaffung ebenderselben wohl noch nie der richtige Mann der richtigen Frau begegnet ist.']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6SyqvRaOWDg",
        "colab_type": "text"
      },
      "source": [
        "The actual data contains over 150,000 sentence-pairs. However, we will use the first 50,000 sentence pairs only to reduce the training time of the model. You can change this number as per you system computation power.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAhDbV_GOJ8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deu_eng = deu_eng[:50000,:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prG2q7lkOfcz",
        "colab_type": "text"
      },
      "source": [
        "# **Text Pre-Processing**\n",
        "\n",
        "**Text Cleaning**\n",
        "\n",
        "We will get rid of the punctuation marks, and then convert the text to lower case.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P06VbROSOZjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove punctuation\n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I7CAp0NPIdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "8b7617c6-aba8-4c75-b571-2d821b2c6f4e"
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Hi', 'Hallo'],\n",
              "       ['Hi', 'Grüß Gott'],\n",
              "       ['Run', 'Lauf'],\n",
              "       ...,\n",
              "       ['The man died of cancer', 'Der Mann starb an Krebs'],\n",
              "       ['The man lay motionless', 'Der Mann lag bewegungslos da'],\n",
              "       ['The man must be insane', 'Der Mann muss geistesgestört sein']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YruuhctPL2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to lowercase\n",
        "for i in range(len(deu_eng)):\n",
        "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
        "    \n",
        "    deu_eng[i,1] = deu_eng[i,1].lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW_qAQclPTS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b5f7bdab-6758-4b25-ea93-8e0cf2188a51"
      },
      "source": [
        "deu_eng\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['hi', 'hallo'],\n",
              "       ['hi', 'grüß gott'],\n",
              "       ['run', 'lauf'],\n",
              "       ...,\n",
              "       ['the man died of cancer', 'der mann starb an krebs'],\n",
              "       ['the man lay motionless', 'der mann lag bewegungslos da'],\n",
              "       ['the man must be insane', 'der mann muss geistesgestört sein']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urfb6p0ZPgXS",
        "colab_type": "text"
      },
      "source": [
        "**Text to Sequence Conversion**\n",
        "\n",
        "\n",
        "To feed our data in a Seq2Seq model, we will have to convert both the input and the output sentences into integer sequences of fixed length. Before that, let's visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and German, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIinJAgMPW8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# empty lists\n",
        "eng_l = []\n",
        "deu_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in deu_eng[:,0]:\n",
        "    eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "    deu_l.append(len(i.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d47JZCKHP103",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApNu5jOAP-mA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "d03aa6ec-6831-4cc1-fe41-82b4c7989109"
      },
      "source": [
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nODmYmVnB/wefhgP5omFI5gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ob80a2eQQOX",
        "colab_type": "text"
      },
      "source": [
        "The maximum length of the German sentences is 11 and that of the English phrases is 8.\n",
        "\n",
        "Let's vectorize our text data by using Keras's Tokenizer() class. It will turn our sentences into sequences of integers. Then we will pad those sequences with zeros to make all the sequences of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe3CraCOQCwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOa3WBvJQZgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d335a6e-1b6e-4157-89a6-e6847804258b"
      },
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 6352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiiuWH41QqmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd0916d4-c26c-4865-f679-ca89eac20aef"
      },
      "source": [
        "# prepare Deutch tokenizer\n",
        "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "\n",
        "deu_length = 11\n",
        "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deutch Vocabulary Size: 10678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2vQ3ye_RCST",
        "colab_type": "text"
      },
      "source": [
        "Given below is a function to prepare the sequences. It will also perform sequence padding to a maximum sentence length as mentioned above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrt4mb3lQubY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQcObUg4Riow",
        "colab_type": "text"
      },
      "source": [
        "**Model Building**\n",
        "\n",
        "We will now split the data into train and test set for model training and evaluation, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OQBz0NJRY4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ir6dqx_RzXS",
        "colab_type": "text"
      },
      "source": [
        "It's time to encode the sentences. We will encode German sentences as the input sequences and English sentences as the target sequences. It will be done for both train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI3s8LUiRtBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUyy-bTpR3Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare validation data\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-mpa9YzSPgl",
        "colab_type": "text"
      },
      "source": [
        "Now comes the exciting part! Let us define our Seq2Seq model architecture. We are using an Embedding layer and an LSTM layer as our encoder and another LSTM layer followed by a Dense layer as the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-okTQO6TR7Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build NMT model\n",
        "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "    model.add(LSTM(units))\n",
        "    model.add(RepeatVector(out_timesteps))\n",
        "    model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(Dense(out_vocab, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lXg3ZocSrjl",
        "colab_type": "text"
      },
      "source": [
        "We are using RMSprop optimizer in this model as it is usually a good choice for recurrent neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1dZLsnMSoAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "37f3aa26-46c4-4abd-d6d9-66ef541fa30a"
      },
      "source": [
        "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0830 11:34:13.226854 140163629475712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0830 11:34:13.278398 140163629475712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0830 11:34:13.284222 140163629475712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0830 11:34:14.253954 140163629475712 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0830 11:34:15.279459 140163629475712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0830 11:34:15.287209 140163629475712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDpXD4AnTk2k",
        "colab_type": "text"
      },
      "source": [
        "Please note that we have used 'sparse_categorical_crossentropy' as the loss function because it allows us to use the target sequence as it is instead of one hot encoded format. One hot encoding the target sequences with such a huge vocabulary might consume our system's entire memory.\n",
        "\n",
        "It seems we are all set to start training our model. We will train it for 30 epochs and with a batch size of 512. You may change and play these hyperparameters. We will also be using ModelCheckpoint() to save the best model with lowest validation loss. I personally prefer this method over early stopping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhtQq_lITeoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b24df8d2-87fd-4151-dbfd-f574512f53fe"
      },
      "source": [
        "filename = 'model.h1.30_aug_19'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
        "          epochs=30, batch_size=512, \n",
        "          validation_split = 0.2,\n",
        "          callbacks=[checkpoint], verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0830 11:36:34.984956 140163629475712 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/30\n",
            "32000/32000 [==============================] - 14s 439us/step - loss: 3.5474 - val_loss: 2.9592\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.95915, saving model to model.h1.30_aug_19\n",
            "Epoch 2/30\n",
            "32000/32000 [==============================] - 8s 239us/step - loss: 2.8970 - val_loss: 2.8455\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.95915 to 2.84553, saving model to model.h1.30_aug_19\n",
            "Epoch 3/30\n",
            "32000/32000 [==============================] - 8s 240us/step - loss: 2.7277 - val_loss: 2.7317\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.84553 to 2.73173, saving model to model.h1.30_aug_19\n",
            "Epoch 4/30\n",
            "32000/32000 [==============================] - 8s 241us/step - loss: 2.5490 - val_loss: 2.5972\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.73173 to 2.59717, saving model to model.h1.30_aug_19\n",
            "Epoch 5/30\n",
            "32000/32000 [==============================] - 8s 243us/step - loss: 2.3873 - val_loss: 2.4212\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.59717 to 2.42115, saving model to model.h1.30_aug_19\n",
            "Epoch 6/30\n",
            "32000/32000 [==============================] - 8s 244us/step - loss: 2.2409 - val_loss: 2.3473\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.42115 to 2.34732, saving model to model.h1.30_aug_19\n",
            "Epoch 7/30\n",
            "32000/32000 [==============================] - 8s 245us/step - loss: 2.1075 - val_loss: 2.2229\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.34732 to 2.22287, saving model to model.h1.30_aug_19\n",
            "Epoch 8/30\n",
            "32000/32000 [==============================] - 8s 245us/step - loss: 1.9848 - val_loss: 2.1351\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.22287 to 2.13507, saving model to model.h1.30_aug_19\n",
            "Epoch 9/30\n",
            "32000/32000 [==============================] - 8s 248us/step - loss: 1.8706 - val_loss: 2.0455\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.13507 to 2.04549, saving model to model.h1.30_aug_19\n",
            "Epoch 10/30\n",
            "32000/32000 [==============================] - 8s 249us/step - loss: 1.7610 - val_loss: 2.0157\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.04549 to 2.01567, saving model to model.h1.30_aug_19\n",
            "Epoch 11/30\n",
            "32000/32000 [==============================] - 8s 251us/step - loss: 1.6610 - val_loss: 1.9287\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.01567 to 1.92869, saving model to model.h1.30_aug_19\n",
            "Epoch 12/30\n",
            "32000/32000 [==============================] - 8s 252us/step - loss: 1.5625 - val_loss: 1.8523\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.92869 to 1.85231, saving model to model.h1.30_aug_19\n",
            "Epoch 13/30\n",
            "32000/32000 [==============================] - 8s 254us/step - loss: 1.4701 - val_loss: 1.7867\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.85231 to 1.78668, saving model to model.h1.30_aug_19\n",
            "Epoch 14/30\n",
            "32000/32000 [==============================] - 8s 254us/step - loss: 1.3801 - val_loss: 1.7529\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.78668 to 1.75289, saving model to model.h1.30_aug_19\n",
            "Epoch 15/30\n",
            "32000/32000 [==============================] - 8s 254us/step - loss: 1.2973 - val_loss: 1.7025\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.75289 to 1.70250, saving model to model.h1.30_aug_19\n",
            "Epoch 16/30\n",
            "32000/32000 [==============================] - 8s 251us/step - loss: 1.2146 - val_loss: 1.6763\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.70250 to 1.67628, saving model to model.h1.30_aug_19\n",
            "Epoch 17/30\n",
            "32000/32000 [==============================] - 8s 251us/step - loss: 1.1376 - val_loss: 1.6219\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.67628 to 1.62191, saving model to model.h1.30_aug_19\n",
            "Epoch 18/30\n",
            "32000/32000 [==============================] - 8s 250us/step - loss: 1.0624 - val_loss: 1.5963\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.62191 to 1.59625, saving model to model.h1.30_aug_19\n",
            "Epoch 19/30\n",
            "32000/32000 [==============================] - 8s 250us/step - loss: 0.9930 - val_loss: 1.5651\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.59625 to 1.56509, saving model to model.h1.30_aug_19\n",
            "Epoch 20/30\n",
            "32000/32000 [==============================] - 8s 250us/step - loss: 0.9241 - val_loss: 1.5421\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.56509 to 1.54207, saving model to model.h1.30_aug_19\n",
            "Epoch 21/30\n",
            "32000/32000 [==============================] - 8s 250us/step - loss: 0.8592 - val_loss: 1.5140\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.54207 to 1.51404, saving model to model.h1.30_aug_19\n",
            "Epoch 22/30\n",
            "32000/32000 [==============================] - 8s 252us/step - loss: 0.7967 - val_loss: 1.4899\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.51404 to 1.48989, saving model to model.h1.30_aug_19\n",
            "Epoch 23/30\n",
            "32000/32000 [==============================] - 8s 252us/step - loss: 0.7398 - val_loss: 1.4760\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.48989 to 1.47603, saving model to model.h1.30_aug_19\n",
            "Epoch 24/30\n",
            "32000/32000 [==============================] - 8s 251us/step - loss: 0.6873 - val_loss: 1.4609\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.47603 to 1.46092, saving model to model.h1.30_aug_19\n",
            "Epoch 25/30\n",
            "32000/32000 [==============================] - 8s 251us/step - loss: 0.6335 - val_loss: 1.4424\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.46092 to 1.44242, saving model to model.h1.30_aug_19\n",
            "Epoch 26/30\n",
            "32000/32000 [==============================] - 8s 251us/step - loss: 0.5860 - val_loss: 1.4255\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.44242 to 1.42550, saving model to model.h1.30_aug_19\n",
            "Epoch 27/30\n",
            "32000/32000 [==============================] - 8s 250us/step - loss: 0.5384 - val_loss: 1.4324\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.42550\n",
            "Epoch 28/30\n",
            "32000/32000 [==============================] - 8s 251us/step - loss: 0.4951 - val_loss: 1.4251\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.42550 to 1.42511, saving model to model.h1.30_aug_19\n",
            "Epoch 29/30\n",
            "32000/32000 [==============================] - 8s 251us/step - loss: 0.4556 - val_loss: 1.4055\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.42511 to 1.40547, saving model to model.h1.30_aug_19\n",
            "Epoch 30/30\n",
            "32000/32000 [==============================] - 8s 251us/step - loss: 0.4153 - val_loss: 1.4203\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.40547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsHrR6LpXB1Q",
        "colab_type": "text"
      },
      "source": [
        "Let's compare the training loss and the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JKZbWH1UA4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a6781cf1-b89a-4f67-f43c-8b3cf2af0c85"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF0IIB/T/Ae8jsqXC91xhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPDgh0IVYGJD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Make Predictions**\n",
        "\n",
        "\n",
        "Let's load the saved model to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiePCclUXE1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('model.h1.30_aug_19')\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jIZoCh9YTf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeigFLkYdqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert predictions into text (English)\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], eng_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "             \n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)            \n",
        "        \n",
        "    preds_text.append(' '.join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6CKN_TzYxB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxm6mUE9ZOUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEAMmx25ZRAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "3eca1cc6-7fb4-4f03-8213-a5f752e56e90"
      },
      "source": [
        "pred_df.head(15)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>he wanted to be rich</td>\n",
              "      <td>he wanted to rich</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i love tom</td>\n",
              "      <td>i like tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>let us go home</td>\n",
              "      <td>lets go home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i love driving</td>\n",
              "      <td>i prefer to life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is my dictionary</td>\n",
              "      <td>thats my dictionary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hi tom good morning</td>\n",
              "      <td>hi tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>why is she so popular</td>\n",
              "      <td>why is so  popular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ill show you my room</td>\n",
              "      <td>ill show you my room</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>did tom oversleep</td>\n",
              "      <td>has tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>keep up the good work</td>\n",
              "      <td>look to good work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>what happened</td>\n",
              "      <td>what happened</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>toms weak</td>\n",
              "      <td>tom is weak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>take tom home</td>\n",
              "      <td>take tom home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>school is out</td>\n",
              "      <td>school is over</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>it is pitch dark</td>\n",
              "      <td>its rush black</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   actual                 predicted\n",
              "0    he wanted to be rich     he wanted to rich    \n",
              "1              i love tom           i like tom     \n",
              "2          let us go home         lets go home     \n",
              "3          i love driving      i prefer to life    \n",
              "4   this is my dictionary  thats my dictionary     \n",
              "5     hi tom good morning              hi tom      \n",
              "6   why is she so popular     why is so  popular   \n",
              "7    ill show you my room   ill show you my room   \n",
              "8       did tom oversleep             has tom      \n",
              "9   keep up the good work     look to good work    \n",
              "10          what happened       what happened      \n",
              "11              toms weak          tom is weak     \n",
              "12          take tom home        take tom home     \n",
              "13          school is out       school is over     \n",
              "14       it is pitch dark       its rush black     "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o48frPJDZTxU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "10f528a7-d6f5-4bdf-fcc5-e3b8ee9e4475"
      },
      "source": [
        "pred_df.tail(15)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9985</th>\n",
              "      <td>i didnt notice it</td>\n",
              "      <td>i didnt care</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9986</th>\n",
              "      <td>she rode a camel</td>\n",
              "      <td>she gets for a tree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9987</th>\n",
              "      <td>trust me he said</td>\n",
              "      <td>what him me told</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9988</th>\n",
              "      <td>tom grabbed his bag</td>\n",
              "      <td>tom has his nose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9989</th>\n",
              "      <td>what was tom like</td>\n",
              "      <td>how did tom like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9990</th>\n",
              "      <td>it looks like snow</td>\n",
              "      <td>it looks snow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>tom works slowly</td>\n",
              "      <td>tom is slowly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>i love rock</td>\n",
              "      <td>i like to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>our tv isnt working</td>\n",
              "      <td>our black is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>youre a racist</td>\n",
              "      <td>youre a  workaholic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>i have one question</td>\n",
              "      <td>i  an answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>i find swimming fun</td>\n",
              "      <td>ok is fun at me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>tom usually wins</td>\n",
              "      <td>tom seemed back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>he deserves the prize</td>\n",
              "      <td>he is the rules</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>ill explain later</td>\n",
              "      <td>ill try it later</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     actual                predicted\n",
              "9985      i didnt notice it        i didnt care     \n",
              "9986       she rode a camel   she gets for a tree   \n",
              "9987       trust me he said     what him me told    \n",
              "9988    tom grabbed his bag     tom has his nose    \n",
              "9989      what was tom like     how did tom like    \n",
              "9990     it looks like snow       it looks snow     \n",
              "9991       tom works slowly       tom is slowly     \n",
              "9992            i love rock           i like to     \n",
              "9993    our tv isnt working        our black is     \n",
              "9994         youre a racist  youre a  workaholic    \n",
              "9995    i have one question         i  an answer    \n",
              "9996    i find swimming fun       ok is fun at me   \n",
              "9997       tom usually wins     tom seemed back     \n",
              "9998  he deserves the prize      he is the rules    \n",
              "9999      ill explain later     ill try it later    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHdktwSQZeDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "0ff8cc1f-adb5-44cf-93be-97aedc7558d0"
      },
      "source": [
        "pred_df.sample(15)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7430</th>\n",
              "      <td>tom isnt done</td>\n",
              "      <td>tom isnt ready</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4867</th>\n",
              "      <td>my cat loves catnip</td>\n",
              "      <td>my cat loves white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9371</th>\n",
              "      <td>happy easter</td>\n",
              "      <td>tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7914</th>\n",
              "      <td>she trusts him</td>\n",
              "      <td>she trusted him</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4464</th>\n",
              "      <td>you were so sweet</td>\n",
              "      <td>youre were curious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7080</th>\n",
              "      <td>im optimistic</td>\n",
              "      <td>im am</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8177</th>\n",
              "      <td>we were robbed</td>\n",
              "      <td>we got robbed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>tom is sneaky</td>\n",
              "      <td>tom is jealous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2350</th>\n",
              "      <td>lets go</td>\n",
              "      <td>lets go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6890</th>\n",
              "      <td>dont get fat</td>\n",
              "      <td>dont not fat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>dont mess with tom</td>\n",
              "      <td>dont mess with tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4535</th>\n",
              "      <td>the boys are fine</td>\n",
              "      <td>the boys are well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2481</th>\n",
              "      <td>write your full name</td>\n",
              "      <td>her your her</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1321</th>\n",
              "      <td>please get tom</td>\n",
              "      <td>please go tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1070</th>\n",
              "      <td>you may quote me</td>\n",
              "      <td>you must study up</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    actual                predicted\n",
              "7430         tom isnt done      tom isnt ready     \n",
              "4867   my cat loves catnip   my cat loves white    \n",
              "9371          happy easter               tom       \n",
              "7914        she trusts him     she trusted him     \n",
              "4464     you were so sweet  youre were curious     \n",
              "7080         im optimistic              im am      \n",
              "8177        we were robbed       we got robbed     \n",
              "217          tom is sneaky      tom is jealous     \n",
              "2350               lets go            lets go      \n",
              "6890          dont get fat        dont not fat     \n",
              "7918    dont mess with tom   dont mess with tom    \n",
              "4535     the boys are fine    the boys are well    \n",
              "2481  write your full name        her your her     \n",
              "1321        please get tom       please go tom     \n",
              "1070      you may quote me    you must study up    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOEcEBzZZkQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}